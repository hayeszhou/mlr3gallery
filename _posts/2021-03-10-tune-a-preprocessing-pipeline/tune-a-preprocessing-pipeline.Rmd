---
title: Tune a Preprocessing Pipeline
description: 
  In this post, we build a simple preprocessing pipeline and tune it.
author:
  - name: Marc Becker
date: 03-10-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(
  echo = TRUE,
  R.options = list(width = 80)
)
library(mlr3book)
```


# Scope

In this post, we build a simple preprocessing pipeline and tune it.
For this, we are using the `r mlr_pkg("mlr3pipelines")` extension package.
First, we start by imputing missing values in the [Pima Indians Diabetes data set](https://mlr3.mlr-org.com/reference/mlr_tasks_pima.html).
After that, we encode a factor column to numerical dummy columns in the data set.
Next, we combine both preprocessing steps to a `r ref("Graph")` and create a `r ref("GraphLearner")`.
Finally, nested resampling is used to compare the performance of two imputation methods.

# Prerequisites

We load the `r mlr_pkg("mlr3verse")`  package which pulls in the most important packages for this example.

```{r, message = FALSE}
library(mlr3verse)
```

We initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.
The [`lgr`](https://mlr3book.mlr-org.com/logging.html) package is used for logging in all `r mlr_pkg("mlr3")` packages.
The `r mlr_pkg("mlr3")` logger prints the logging messages from the base package, whereas the `r mlr_pkg("bbotk")`  logger is responsible for logging messages from the optimization packages (e.g. `r mlr_pkg("mlr3tuning")` ).

```{r}
set.seed(7832)
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
```

In this example, we use the [Pima Indians Diabetes data set](https://mlr3.mlr-org.com/reference/mlr_tasks_pima.html) which is used to predict whether or not a patient has diabetes.
The patients are characterized by 8 numeric features of which some have missing values.
We alter the data set by categorizing the feature `pressure` (blood pressure) into the categories `"low"`, `"mid"`, and `"high"`.

```{r}
# retrieve the task from mlr3
task = tsk("pima")

# create data frame with categorized pressure feature
data = task$data(cols = "pressure")
breaks = quantile(data$pressure, probs = c(0, 0.33, 0.66, 1), na.rm = TRUE)
data$pressure = cut(data$pressure, breaks, labels = c("low", "mid", "high"))

# overwrite the feature in the task
task$cbind(data)

# generate a quick textual overview
skimr::skim(task$data())
```

We choose the xgboost algorithm from the `r cran_pkg("xgboost")` package as learner.

```{r}
learner = lrn("classif.xgboost", nrounds = 100, id = "xgboost", verbose = 0)
```

# Missing Values

The task has missing data in five columns.

```{r}
round(task$missings() / task$nrow, 2)
```

The `xgboost` learner has an internal method for handling missing data but some learners cannot handle missing values.
We will try to beat the internal method in terms of predictive performance.
The `r mlr_pkg("mlr3pipelines")` package offers various methods to impute missing values.

```{r}
mlr_pipeops$keys("^impute")
```

We choose the `r ref("PipeOpImputeOOR")` that adds the new factor level `".MISSING".` to factorial features and imputes numerical features by constant values shifted below the minimum (default) or above the maximum.

```{r}
imputer = po("imputeoor")
print(imputer)
```

As the output suggests, the in- and output of this pipe operator is a `r ref("Task")` for both the training and the predict step.
We can manually train the pipe operator to check its functionality:

```{r}
task_imputed = imputer$train(list(task))[[1]]
task_imputed$missings()
```

Let's compare an observation with missing values to the observation with imputed observation.

```{r}
rbind(
  task$data()[8,],
  task_imputed$data()[8,]
)
```

Note that OOR imputation is in particular useful for tree-based models, but should not be used for linear models or distance-based models.

# Factor Encoding

The `xgboost` learner cannot handle categorical features.
Therefore, we must to convert factor columns to numerical dummy columns.
For this, we argument the `xgboost` learner with automatic factor encoding.

The `r ref("PipeOpEncode")` encodes factor columns with one of six methods.
In this example, we use `one-hot` encoding which creates a new binary column for each factor level.

```{r}
factor_encoding = po("encode", method = "one-hot")
```

We manually trigger the encoding on the task.

```{r}
factor_encoding$train(list(task))
```

The factor column `pressure` has been converted to the three binary columns `"pressure.low"`, `"pressure.mid"`, and `"pressure.high"`.

# Constructing the Pipeline

We created two preprocessing steps which could be used to create a new task with encoded factor variables and imputed missing values.
However, if we do this before resampling, information from the test can leak into our training step which typically leads to overoptimistic performance measures.
To avoid this, we add the preprocessing steps to the `r ref("Learner")` itself, creating a `r ref("GraphLearner")`.
For this, we create a `r ref("Graph")` first.

```{r}
graph = po("encode") %>>%
  po("imputeoor") %>>%
  learner
plot(graph)
```

We wrap the `r ref("Graph")` into `r ref("GraphLearner")` which allows us to use the graph like a normal learner.

```{r}
graph_learner = GraphLearner$new(graph)

# short learner id for printing
graph_learner$id = "graph_learner"
```

The `r ref("GraphLearner")` can be trained and used for making predictions.
Instead of calling `$train()` or `$predict()` manually, we will directly use it for resampling.
We choose a 3-fold cross-validation as the resampling strategy.

```{r, results = 'hide'}
resampling = rsmp("cv", folds = 3)

rr = resample(task = task, learner = graph_learner, resampling = resampling)
```

```{r}
rr$score()
```

For each resampling iteration, the following steps are performed:

1. The task is subsetted to the training indices.
2. The factor encoder replaces factor features with dummy columns in the training task.
3. The OOR imputer determines values to impute from the training task and then replaces all missing values with learned imputation values.
4. The learner is applied on the modified training task and the model is stored inside the learner.

Next is the predict step:

1. The task is subsetted to the test indices.
2. The factor encoder replaces all factor features with dummy columns in the test task.
3. The OOR imputer replaces all missing values of the test task with the imputation values learned on the training set.
4. The learner's predict method is applied on the modified test task.

By following this procedure, it is guaranteed that no information can leak from the training step to the predict step.

# Tuning the Pipeline

Let's have a look at the parameter set of the `r ref("GraphLearner")`.
It consists of the `xgboost` hyperparameters, and additionally, the parameter of the  `r ref("PipeOp")` `encode` and `imputeoor`.
All hyperparameters are prefixed with the id of the respective `r ref("PipeOp")` or learner.

```{r}
print(graph_learner$param_set)
```

We will tune the encode method.

```{r}
graph_learner$param_set$values$encode.method = to_tune(c("one-hot", "treatment"))
```

We define a tuning instance and use grid search since we want to try all encode methods.

```{r, results = 'hide'}
instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = graph_learner,
  resampling = resampling,
  measure = msr("classif.ce"),
  terminator = trm("none")
)

tuner = tnr("grid_search")
tuner$optimize(instance)
```

The archive shows us the performance of the model with different encoding methods.

```{r}
print(instance$archive)
```

# Nested Resampling

We create one `r ref("GraphLearner")` with `imputeoor` and test it against a `r ref("GraphLearner")` that uses the internal imputation method of `xgboost`.
Applying nested resampling ensures a fair comparison of the predictive performances.

```{r}
graph_1 = po("encode") %>>%
  learner
graph_learner_1 = GraphLearner$new(graph_1)

graph_learner_1$param_set$values$encode.method = to_tune(c("one-hot", "treatment"))

at_1 = AutoTuner$new(
  learner = graph_learner_1,
  resampling = resampling,
  measure = msr("classif.ce"),
  terminator = trm("none"),
  tuner = tnr("grid_search"),
  store_models = TRUE
)
```

```{r}
graph_2 = po("encode") %>>%
  po("imputeoor") %>>%
  learner
graph_learner_2 = GraphLearner$new(graph_2)

graph_learner_2$param_set$values$encode.method = to_tune(c("one-hot", "treatment"))

at_2 = AutoTuner$new(
  learner = graph_learner_2,
  resampling = resampling,
  measure = msr("classif.ce"),
  terminator = trm("none"),
  tuner = tnr("grid_search"),
  store_models = TRUE
)
```

We run the benchmark.

```{r, echo = FALSE}
bmr = readRDS("data/bmr_1.rda")
```

```{r, eval = FALSE}
resampling_outer = rsmp("cv", folds = 3)
design = benchmark_grid(task, list(at_1, at_2), resampling_outer)

bmr = benchmark(design, store_models = TRUE)
```

We compare the aggregated performances on the outer test sets which give us an unbiased performance estimate of the `r ref("GraphLearner")`s with the different encoding methods.

```{r}
bmr$aggregate()
autoplot(bmr)
```

Note that in practice, it is required to tune preprocessing hyperparameters jointly with the hyperparameters of the learner.
Otherwise, comparing preprocessing steps is not feasible and can lead to wrong conclusions.

# Final Model

We train the chosen `r ref("GraphLearner")` with the `r ref("AutoTuner")` to get a final model with optimized hyperparameters.

```{r, eval = FALSE}
at_2$train(task)
```

The trained model can now be used to make predictions on new data `at_2$predict()`.
The pipeline ensures that the preprocessing is always a part of the train and predict step.

# Resources

The [mlr3book](https://mlr3book.mlr-org.com/) includes chapters on [pipelines](https://mlr3book.mlr-org.com/pipelines.html) and [hyperparameter tuning](https://mlr3book.mlr-org.com/tuning.html). 
The [mlr3cheatsheets](https://cheatsheets.mlr-org.com/) contain frequently used commands and workflows of mlr3.
